{
 "cells": [
  {
   "cell_type": "raw",
   "id": "191f38c1",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Обработка книг по продажам\n",
    "\n",
    "Этот блокнот обрабатывает FB2 файлы книг по продажам недвижимости и извлекает из них техники продаж, диалоги и примеры.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88742cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорты и настройка\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b96447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceBasedProcessor:\n",
    "    \"\"\"Процессор на основе целых предложений и осмысленных фраз\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Паттерны для поиска готовых техник и диалогов\n",
    "        self.technique_patterns = {\n",
    "            'выявление_потребностей': [\n",
    "                r'[А-ЯЁ][^.!?]*(?:что|как|почему|когда|где|какой|какая|какие)[^.!?]*\\?',\n",
    "                r'[А-ЯЁ][^.!?]*(?:расскажите|объясните|опишите|поделитесь)[^.!?]*[.!?]',\n",
    "                r'[А-ЯЁ][^.!?]*(?:важно|интересует|волнует|беспокоит)[^.!?]*\\?',\n",
    "                r'[А-ЯЁ][^.!?]*(?:потребност|нужд|требован)[^.!?]*[.!?]',\n",
    "                r'[А-ЯЁ][^.!?]*СПИН[^.!?]*[.!?]'\n",
    "            ],\n",
    "            'презентация_объектов': [\n",
    "                r'[А-ЯЁ][^.!?]*(?:это означает что|благодаря этому|в результате)[^.!?]*[.!?]',\n",
    "                r'[А-ЯЁ][^.!?]*(?:представьте себе|посмотрите|обратите внимание)[^.!?]*[.!?]',\n",
    "                r'[А-ЯЁ][^.!?]*(?:выгода|преимущество|польза)[^.!?]*[.!?]',\n",
    "                r'[А-ЯЁ][^.!?]*(?:квартира|дом|объект)[^.!?]*(?:характеристик|особенност)[^.!?]*[.!?]'\n",
    "            ],\n",
    "            'работа_с_возражениями': [\n",
    "                r'[А-ЯЁ][^.!?]*(?:понимаю|согласен)[^.!?]*(?:но|однако|тем не менее)[^.!?]*[.!?]',\n",
    "                r'[А-ЯЁ][^.!?]*(?:возражение|сомнение)[^.!?]*[.!?]',\n",
    "                r'[А-ЯЁ][^.!?]*(?:да но да|бумеранг)[^.!?]*[.!?]',\n",
    "                r'[А-ЯЁ][^.!?]*дорого[^.!?]*[.!?]'\n",
    "            ],\n",
    "            'установление_доверия': [\n",
    "                r'[А-ЯЁ][^.!?]*(?:опыт показывает|практика показывает)[^.!?]*[.!?]',\n",
    "                r'[А-ЯЁ][^.!?]*(?:другие клиенты|наши клиенты)[^.!?]*[.!?]',\n",
    "                r'[А-ЯЁ][^.!?]*(?:гарантирую|обещаю|ручаюсь)[^.!?]*[.!?]',\n",
    "                r'[А-ЯЁ][^.!?]*(?:доверие|надежность)[^.!?]*[.!?]'\n",
    "            ],\n",
    "            'закрытие_сделки': [\n",
    "                r'[А-ЯЁ][^.!?]*(?:готовы|согласны)[^.!?]*(?:подписать|оформить|купить)[^.!?]*\\?',\n",
    "                r'[А-ЯЁ][^.!?]*(?:когда удобно|когда вам подходит)[^.!?]*\\?',\n",
    "                r'[А-ЯЁ][^.!?]*(?:выбираете|принимаете решение)[^.!?]*\\?',\n",
    "                r'[А-ЯЁ][^.!?]*(?:первый вариант или второй)[^.!?]*\\?'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Паттерны для поиска диалогов\n",
    "        self.dialog_patterns = [\n",
    "            r'(?:Менеджер|Продавец|Риелтор|Агент):\\s*([^.!?]+[.!?])',\n",
    "            r'(?:Клиент|Покупатель|Заказчик):\\s*([^.!?]+[.!?])',\n",
    "            r'—\\s*([А-ЯЁ][^.!?]+[.!?])',\n",
    "            r'«([^»]+)»[^А-ЯЁ]*говорит'\n",
    "        ]\n",
    "        \n",
    "        # Готовые примеры техник (из теории продаж)\n",
    "        self.theory_examples = {\n",
    "            'выявление_потребностей': [\n",
    "                \"Что для вас важно при выборе квартиры?\",\n",
    "                \"Расскажите о ваших требованиях к жилью.\",\n",
    "                \"Какие факторы влияют на ваше решение?\",\n",
    "                \"Что должно быть в идеальной квартире?\",\n",
    "                \"Как вы представляете свой новый дом?\"\n",
    "            ],\n",
    "            'презентация_объектов': [\n",
    "                \"Это означает, что вы сэкономите час времени каждый день.\",\n",
    "                \"Благодаря этой планировке ваша семья будет чувствовать себя комфортно.\",\n",
    "                \"Представьте, как здорово будет встречать рассветы на этом балконе.\",\n",
    "                \"Эта особенность дает вам преимущество перед соседями.\"\n",
    "            ],\n",
    "            'работа_с_возражениями': [\n",
    "                \"Понимаю ваши сомнения, давайте разберем детали.\",\n",
    "                \"Согласен, цена важна, но посмотрите на выгоды.\",\n",
    "                \"Многие клиенты сначала так думают, но потом понимают.\",\n",
    "                \"Это важный вопрос, спасибо что подняли его.\"\n",
    "            ],\n",
    "            'установление_доверия': [\n",
    "                \"Мой опыт показывает, что это лучшее решение.\",\n",
    "                \"Другие клиенты остались очень довольны.\",\n",
    "                \"Гарантирую, что вы не пожалеете о выборе.\",\n",
    "                \"Наша компания работает на рынке 15 лет.\"\n",
    "            ],\n",
    "            'закрытие_сделки': [\n",
    "                \"Когда вам удобно подписать договор?\",\n",
    "                \"Готовы оформить бронирование сегодня?\",\n",
    "                \"Что выбираете - первый вариант или второй?\",\n",
    "                \"Когда планируете въезжать?\"\n",
    "            ]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9f54e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Методы для извлечения текста из FB2\n",
    "def extract_text_clean(self, file_path):\n",
    "    \"\"\"Чистое извлечение текста\"\"\"\n",
    "    \n",
    "    if file_path.suffix.lower() == '.fb2':\n",
    "        return self.extract_fb2_sentences(file_path)\n",
    "    else:\n",
    "        return self.extract_txt_sentences(file_path)\n",
    "\n",
    "def extract_fb2_sentences(self, fb2_path):\n",
    "    \"\"\"Извлечение FB2 с сохранением структуры предложений\"\"\"\n",
    "    \n",
    "    methods = [\n",
    "        ('xml_parse', self._xml_extract),\n",
    "        ('regex_clean', self._regex_extract),\n",
    "        ('binary_force', self._binary_extract)\n",
    "    ]\n",
    "    \n",
    "    for method_name, method_func in methods:\n",
    "        try:\n",
    "            text = method_func(fb2_path)\n",
    "            if text and len(text) > 1000:\n",
    "                return self.clean_and_structure_text(text)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "def _xml_extract(self, fb2_path):\n",
    "    \"\"\"XML извлечение\"\"\"\n",
    "    tree = ET.parse(fb2_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    paragraphs = []\n",
    "    for elem in root.iter():\n",
    "        if elem.tag and elem.tag.endswith('p') and elem.text:\n",
    "            text = elem.text.strip()\n",
    "            if len(text) > 10:\n",
    "                paragraphs.append(text)\n",
    "    \n",
    "    return '\\n\\n'.join(paragraphs)\n",
    "\n",
    "def _regex_extract(self, fb2_path):\n",
    "    \"\"\"Regex извлечение с попыткой разных кодировок\"\"\"\n",
    "    for encoding in ['utf-8', 'cp1251', 'koi8-r']:\n",
    "        try:\n",
    "            with open(fb2_path, 'r', encoding=encoding) as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            # Более умная очистка\n",
    "            clean_text = re.sub(r'<[^>]*>', '\\n', content)\n",
    "            clean_text = re.sub(r'\\n\\s*\\n', '\\n\\n', clean_text)\n",
    "            \n",
    "            if len(clean_text) > 2000:\n",
    "                return clean_text\n",
    "        except:\n",
    "            continue\n",
    "    return \"\"\n",
    "\n",
    "def _binary_extract(self, fb2_path):\n",
    "    \"\"\"Принудительное извлечение\"\"\"\n",
    "    with open(fb2_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "    \n",
    "    for encoding in ['utf-8', 'cp1251']:\n",
    "        try:\n",
    "            content = raw_data.decode(encoding, errors='ignore')\n",
    "            clean_text = re.sub(r'<[^>]*>', '\\n', content)\n",
    "            if len(clean_text) > 2000:\n",
    "                return clean_text\n",
    "        except:\n",
    "            continue\n",
    "    return \"\"\n",
    "\n",
    "def extract_txt_sentences(self, txt_path):\n",
    "    \"\"\"Извлечение TXT с разными кодировками\"\"\"\n",
    "    for encoding in ['utf-8', 'cp1251', 'koi8-r', 'windows-1252']:\n",
    "        try:\n",
    "            with open(txt_path, 'r', encoding=encoding) as f:\n",
    "                text = f.read()\n",
    "            if len(text) > 500:\n",
    "                return self.clean_and_structure_text(text)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Ошибка при чтении {txt_path.name}: {e}\")\n",
    "            continue\n",
    "    return \"\"\n",
    "\n",
    "def process_multiple_formats(self, file_path):\n",
    "    \"\"\"Обработка разных форматов файлов\"\"\"\n",
    "    file_ext = file_path.suffix.lower()\n",
    "    \n",
    "    if file_ext == '.fb2':\n",
    "        return self.extract_fb2_sentences(file_path)\n",
    "    elif file_ext == '.txt':\n",
    "        return self.extract_txt_sentences(file_path)\n",
    "    elif file_ext in ['.doc', '.docx']:\n",
    "        return self.extract_doc_text(file_path)\n",
    "    elif file_ext == '.pdf':\n",
    "        return self.extract_pdf_text(file_path)\n",
    "    else:\n",
    "        print(f\"⚠️ Неподдерживаемый формат: {file_ext}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_doc_text(self, doc_path):\n",
    "    \"\"\"Извлечение текста из DOC/DOCX файлов\"\"\"\n",
    "    try:\n",
    "        from docx import Document \n",
    "        doc = Document(doc_path)\n",
    "        text = '\\n'.join([paragraph.text for paragraph in doc.paragraphs])\n",
    "        return self.clean_and_structure_text(text) if len(text) > 500 else \"\"\n",
    "    except ImportError:\n",
    "        print(\"⚠️ Установите python-docx для работы с .docx файлами\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Ошибка при чтении {doc_path.name}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_pdf_text(self, pdf_path):\n",
    "    \"\"\"Извлечение текста из PDF файлов\"\"\"\n",
    "    try:\n",
    "        import PyPDF2\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "        return self.clean_and_structure_text(text) if len(text) > 500 else \"\"\n",
    "    except ImportError:\n",
    "        print(\"⚠️ Установите PyPDF2 для работы с .pdf файлами\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Ошибка при чтении {pdf_path.name}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Добавляем методы к классу\n",
    "SentenceBasedProcessor.extract_text_clean = extract_text_clean\n",
    "SentenceBasedProcessor.extract_fb2_sentences = extract_fb2_sentences\n",
    "SentenceBasedProcessor.extract_txt_sentences = extract_txt_sentences\n",
    "SentenceBasedProcessor.process_multiple_formats = process_multiple_formats\n",
    "SentenceBasedProcessor.extract_doc_text = extract_doc_text\n",
    "SentenceBasedProcessor.extract_pdf_text = extract_pdf_text\n",
    "SentenceBasedProcessor._xml_extract = _xml_extract\n",
    "SentenceBasedProcessor._regex_extract = _regex_extract\n",
    "SentenceBasedProcessor._binary_extract = _binary_extract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a8e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем остальные методы к классу\n",
    "def clean_and_structure_text(self, text):\n",
    "    \"\"\"Очистка и структурирование текста\"\"\"\n",
    "    \n",
    "    # Удаляем технический мусор\n",
    "    text = re.sub(r'(?:ISBN|ББК|УДК)[^\\n]*', '', text)\n",
    "    text = re.sub(r'http[^\\s]*', '', text)\n",
    "    text = re.sub(r'\\d{4}-\\d{4}-\\d{4}-\\d{4}', '', text)  # номера\n",
    "    \n",
    "    # Нормализуем пробелы\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "    \n",
    "    # Убираем короткие строки (мусор)\n",
    "    lines = text.split('\\n')\n",
    "    clean_lines = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if (len(line) > 15 and \n",
    "            not line.isdigit() and\n",
    "            not re.match(r'^[A-Z\\s]{5,}$', line)):  # не только заглавные\n",
    "            clean_lines.append(line)\n",
    "    \n",
    "    return '\\n'.join(clean_lines)\n",
    "\n",
    "def find_complete_sentences(self, text, book_name):\n",
    "    \"\"\"Находит ЦЕЛЫЕ предложения с техниками\"\"\"\n",
    "    \n",
    "    found_techniques = []\n",
    "    \n",
    "    # Разбиваем на предложения\n",
    "    sentences = re.split(r'[.!?]+\\s+', text)\n",
    "    \n",
    "    for category, patterns in self.technique_patterns.items():\n",
    "        category_sentences = []\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            for sentence in sentences:\n",
    "                sentence = sentence.strip()\n",
    "                if len(sentence) < 10 or len(sentence) > 300:\n",
    "                    continue\n",
    "                \n",
    "                # Проверяем соответствие паттерну\n",
    "                if re.search(pattern, sentence, re.IGNORECASE):\n",
    "                    # Дополнительная проверка качества\n",
    "                    if self.is_quality_sentence(sentence, category):\n",
    "                        # Восстанавливаем знак препинания\n",
    "                        if not sentence[-1] in '.!?':\n",
    "                            sentence += '.'\n",
    "                        \n",
    "                        category_sentences.append({\n",
    "                            'book': book_name,\n",
    "                            'category': category,\n",
    "                            'technique': sentence,\n",
    "                            'source': 'extracted',\n",
    "                            'quality': self.rate_sentence_quality(sentence, category)\n",
    "                        })\n",
    "        \n",
    "        # Сортируем по качеству и берем лучшие\n",
    "        category_sentences.sort(key=lambda x: x['quality'], reverse=True)\n",
    "        found_techniques.extend(category_sentences[:10])  # Топ-10 на категорию\n",
    "    \n",
    "    return found_techniques\n",
    "\n",
    "def find_dialogs(self, text, book_name):\n",
    "    \"\"\"Находит готовые диалоги\"\"\"\n",
    "    \n",
    "    dialogs = []\n",
    "    \n",
    "    for pattern in self.dialog_patterns:\n",
    "        matches = re.finditer(pattern, text, re.IGNORECASE)\n",
    "        for match in matches:\n",
    "            dialog_text = match.group(1).strip()\n",
    "            if self.is_quality_dialog(dialog_text):\n",
    "                dialogs.append({\n",
    "                    'book': book_name,\n",
    "                    'category': 'диалог_пример',\n",
    "                    'technique': dialog_text,\n",
    "                    'source': 'dialog',\n",
    "                    'quality': 9\n",
    "                })\n",
    "    \n",
    "    return dialogs[:15]\n",
    "\n",
    "def is_quality_sentence(self, sentence, category):\n",
    "    \"\"\"Проверка качества предложения\"\"\"\n",
    "    \n",
    "    sentence_lower = sentence.lower()\n",
    "    \n",
    "    # Базовые проверки\n",
    "    if any(junk in sentence_lower for junk in ['isbn', 'ббк', 'удк', 'http']):\n",
    "        return False\n",
    "    \n",
    "    # Должно содержать релевантные слова\n",
    "    relevant_words = {\n",
    "        'выявление_потребностей': ['клиент', 'вопрос', 'нужно', 'важно', 'требование'],\n",
    "        'презентация_объектов': ['квартира', 'дом', 'выгода', 'преимущество', 'особенность'],\n",
    "        'работа_с_возражениями': ['возражение', 'сомнение', 'понимаю', 'согласен'],\n",
    "        'установление_доверия': ['доверие', 'опыт', 'клиенты', 'гарантия'],\n",
    "        'закрытие_сделки': ['готовы', 'решение', 'выбор', 'покупка', 'договор']\n",
    "    }\n",
    "    \n",
    "    category_words = relevant_words.get(category, [])\n",
    "    return any(word in sentence_lower for word in category_words)\n",
    "\n",
    "def is_quality_dialog(self, dialog_text):\n",
    "    \"\"\"Проверка качества диалога\"\"\"\n",
    "    return (len(dialog_text) > 10 and \n",
    "            len(dialog_text) < 200 and\n",
    "            any(word in dialog_text.lower() for word in ['клиент', 'квартир', 'покуп', 'продаж']))\n",
    "\n",
    "def rate_sentence_quality(self, sentence, category):\n",
    "    \"\"\"Оценка качества предложения\"\"\"\n",
    "    score = 5  # базовый\n",
    "    \n",
    "    # Бонусы\n",
    "    if '?' in sentence:\n",
    "        score += 2\n",
    "    if any(word in sentence.lower() for word in ['клиент', 'покупатель']):\n",
    "        score += 1\n",
    "    if len(sentence.split()) > 5:\n",
    "        score += 1\n",
    "    if sentence[0].isupper():\n",
    "        score += 1\n",
    "    \n",
    "    return min(10, score)\n",
    "\n",
    "def add_theory_examples(self, found_techniques):\n",
    "    \"\"\"Добавляет готовые примеры из теории\"\"\"\n",
    "    \n",
    "    for category, examples in self.theory_examples.items():\n",
    "        for example in examples:\n",
    "            found_techniques.append({\n",
    "                'book': 'theory_base',\n",
    "                'category': 'базовая_теория',\n",
    "                'technique': example,\n",
    "                'source': 'theory',\n",
    "                'quality': 10\n",
    "            })\n",
    "    \n",
    "    return found_techniques\n",
    "\n",
    "# Добавляем все методы к классу\n",
    "SentenceBasedProcessor.clean_and_structure_text = clean_and_structure_text\n",
    "SentenceBasedProcessor.find_complete_sentences = find_complete_sentences\n",
    "SentenceBasedProcessor.find_dialogs = find_dialogs\n",
    "SentenceBasedProcessor.is_quality_sentence = is_quality_sentence\n",
    "SentenceBasedProcessor.is_quality_dialog = is_quality_dialog\n",
    "SentenceBasedProcessor.rate_sentence_quality = rate_sentence_quality\n",
    "SentenceBasedProcessor.add_theory_examples = add_theory_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fdf56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем экземпляр процессора и запускаем обработку\n",
    "processor = SentenceBasedProcessor()\n",
    "\n",
    "# Обрабатываем все книги (поддерживаем разные форматы)\n",
    "books_dir = Path(\"books\")\n",
    "all_files = (list(books_dir.glob(\"*.fb2\")) + \n",
    "             list(books_dir.glob(\"*.txt\")) + \n",
    "             list(books_dir.glob(\"*.docx\")) + \n",
    "             list(books_dir.glob(\"*.doc\")) + \n",
    "             list(books_dir.glob(\"*.pdf\")))\n",
    "\n",
    "print(\"✨ ОБРАБОТКА НА ОСНОВЕ ЦЕЛЫХ ПРЕДЛОЖЕНИЙ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"📁 Файлов: {len(all_files)}\")\n",
    "print()\n",
    "\n",
    "all_techniques = []\n",
    "book_stats = {}\n",
    "\n",
    "for file_path in all_files:\n",
    "    print(f\"📖 {file_path.name}\")\n",
    "    \n",
    "    text = processor.process_multiple_formats(file_path)\n",
    "    if text:\n",
    "        # Ищем предложения с техниками\n",
    "        sentences = processor.find_complete_sentences(text, file_path.name)\n",
    "        \n",
    "        # Ищем диалоги\n",
    "        dialogs = processor.find_dialogs(text, file_path.name)\n",
    "        \n",
    "        book_techniques = sentences + dialogs\n",
    "        all_techniques.extend(book_techniques)\n",
    "        book_stats[file_path.name] = len(book_techniques)\n",
    "        \n",
    "        print(f\"   ✅ Найдено: {len(book_techniques)} качественных техник\")\n",
    "    else:\n",
    "        print(f\"   ❌ Не удалось извлечь\")\n",
    "        book_stats[file_path.name] = 0\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Добавляем теоретические примеры\n",
    "all_techniques = processor.add_theory_examples(all_techniques)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"🎉 РЕЗУЛЬТАТЫ ОБРАБОТКИ:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"📚 Обработано книг: {len([b for b, c in book_stats.items() if c > 0])}\")\n",
    "print(f\"✨ Всего техник: {len(all_techniques)}\")\n",
    "print(f\"\\n📖 Техники по книгам:\")\n",
    "for book, count in book_stats.items():\n",
    "    if count > 0:\n",
    "        short_name = book[:40] + \"...\" if len(book) > 40 else book\n",
    "        print(f\"  {short_name}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем результаты в CSV\n",
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# CSV с читаемыми техниками\n",
    "csv_path = data_dir / \"quality_techniques.csv\"\n",
    "with open(csv_path, 'w', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "    writer.writerow(['book', 'category', 'source', 'quality', 'sales_technique'])\n",
    "    for technique in all_techniques:\n",
    "        book = technique['book']\n",
    "        category = technique['category']\n",
    "        source = technique['source']\n",
    "        quality = technique['quality']\n",
    "        text = technique['technique'].replace('\\n', ' ')\n",
    "        writer.writerow([book, category, source, quality, text])\n",
    "\n",
    "print(f\"💾 Сохранено в: {csv_path}\")\n",
    "print(f\"📊 Всего записей: {len(all_techniques)}\")\n",
    "\n",
    "# Загружаем DataFrame для анализа\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"\\n📋 Структура данных:\")\n",
    "print(df.info())\n",
    "print(f\"\\n📈 Первые 5 записей:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d02e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Анализ качества извлеченных техник\n",
    "\n",
    "# Импорты для визуализации\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Базовая статистика\n",
    "print(\"📊 АНАЛИЗ КАЧЕСТВА ДАННЫХ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"📚 Общая статистика:\")\n",
    "print(f\"   • Всего техник: {len(df)}\")\n",
    "print(f\"   • Уникальных книг: {df['book'].nunique()}\")\n",
    "print(f\"   • Категорий: {df['category'].nunique()}\")\n",
    "print(f\"   • Источников: {df['source'].nunique()}\")\n",
    "\n",
    "print(f\"\\n🏆 Распределение по качеству:\")\n",
    "quality_counts = df['quality'].value_counts().sort_index()\n",
    "for quality, count in quality_counts.items():\n",
    "    percentage = count / len(df) * 100\n",
    "    print(f\"   • Качество {quality}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n📖 Распределение по категориям:\")\n",
    "category_counts = df['category'].value_counts()\n",
    "for category, count in category_counts.items():\n",
    "    percentage = count / len(df) * 100\n",
    "    print(f\"   • {category}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n📚 Распределение по книгам:\")\n",
    "book_counts = df['book'].value_counts()\n",
    "for book, count in book_counts.items():\n",
    "    percentage = count / len(df) * 100\n",
    "    short_name = book[:35] + \"...\" if len(book) > 35 else book\n",
    "    print(f\"   • {short_name}: {count} ({percentage:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946964cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация результатов обработки\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('📊 Анализ качества извлеченных техник продаж', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Распределение по качеству\n",
    "ax1 = axes[0, 0]\n",
    "quality_counts.plot(kind='bar', ax=ax1, color='skyblue', edgecolor='navy')\n",
    "ax1.set_title('🏆 Распределение по качеству')\n",
    "ax1.set_xlabel('Оценка качества')\n",
    "ax1.set_ylabel('Количество техник')\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Добавляем значения на столбцы\n",
    "for i, v in enumerate(quality_counts.values):\n",
    "    ax1.text(i, v + 0.5, str(v), ha='center', va='bottom')\n",
    "\n",
    "# 2. Распределение по категориям\n",
    "ax2 = axes[0, 1]\n",
    "category_counts.plot(kind='bar', ax=ax2, color='lightgreen', edgecolor='darkgreen')\n",
    "ax2.set_title('📖 Распределение по категориям')\n",
    "ax2.set_xlabel('Категория')\n",
    "ax2.set_ylabel('Количество техник')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Добавляем значения на столбцы\n",
    "for i, v in enumerate(category_counts.values):\n",
    "    ax2.text(i, v + 0.5, str(v), ha='center', va='bottom')\n",
    "\n",
    "# 3. Распределение по книгам (топ-7)\n",
    "ax3 = axes[1, 0]\n",
    "book_counts.head(7).plot(kind='bar', ax=ax3, color='coral', edgecolor='darkred')\n",
    "ax3.set_title('📚 Топ-7 книг по количеству техник')\n",
    "ax3.set_xlabel('Книга')\n",
    "ax3.set_ylabel('Количество техник')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Сокращаем названия книг для лучшего отображения\n",
    "labels = [label.get_text()[:20] + '...' if len(label.get_text()) > 20 else label.get_text() \n",
    "          for label in ax3.get_xticklabels()]\n",
    "ax3.set_xticklabels(labels)\n",
    "\n",
    "# Добавляем значения на столбцы\n",
    "for i, v in enumerate(book_counts.head(7).values):\n",
    "    ax3.text(i, v + 0.5, str(v), ha='center', va='bottom')\n",
    "\n",
    "# 4. Качество по источникам\n",
    "ax4 = axes[1, 1]\n",
    "source_quality = df.groupby('source')['quality'].mean()\n",
    "source_quality.plot(kind='bar', ax=ax4, color='plum', edgecolor='purple')\n",
    "ax4.set_title('📈 Среднее качество по источникам')\n",
    "ax4.set_xlabel('Источник')\n",
    "ax4.set_ylabel('Среднее качество')\n",
    "ax4.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Добавляем значения на столбцы\n",
    "for i, v in enumerate(source_quality.values):\n",
    "    ax4.text(i, v + 0.05, f'{v:.1f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Детальный анализ техник по категориям\n",
    "\n",
    "print(\"🔍 ДЕТАЛЬНЫЙ АНАЛИЗ ПО КАТЕГОРИЯМ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "categories = df['category'].unique()\n",
    "\n",
    "for category in sorted(categories):\n",
    "    category_df = df[df['category'] == category]\n",
    "    print(f\"\\n📋 {category.upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"   • Всего техник: {len(category_df)}\")\n",
    "    print(f\"   • Среднее качество: {category_df['quality'].mean():.1f}\")\n",
    "    print(f\"   • Мин/Макс качество: {category_df['quality'].min()}/{category_df['quality'].max()}\")\n",
    "    \n",
    "    # Источники для категории\n",
    "    sources = category_df['source'].value_counts()\n",
    "    print(f\"   • Источники: {dict(sources)}\")\n",
    "    \n",
    "    # Топ-3 техники по качеству\n",
    "    top_techniques = category_df.nlargest(3, 'quality')\n",
    "    print(f\"   • Топ-3 техники:\")\n",
    "    for idx, (_, row) in enumerate(top_techniques.iterrows(), 1):\n",
    "        technique_preview = row['sales_technique'][:80] + \"...\" if len(row['sales_technique']) > 80 else row['sales_technique']\n",
    "        print(f\"     {idx}. [{row['quality']}⭐] {technique_preview}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeb587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ длины и качества техник\n",
    "\n",
    "# Добавляем столбец с длиной техник\n",
    "df['technique_length'] = df['sales_technique'].str.len()\n",
    "\n",
    "print(\"📏 АНАЛИЗ ДЛИНЫ ТЕХНИК\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"   • Средняя длина: {df['technique_length'].mean():.0f} символов\")\n",
    "print(f\"   • Медианная длина: {df['technique_length'].median():.0f} символов\")\n",
    "print(f\"   • Мин/Макс длина: {df['technique_length'].min()}/{df['technique_length'].max()}\")\n",
    "\n",
    "# Корреляция между длиной и качеством\n",
    "correlation = df['technique_length'].corr(df['quality'])\n",
    "print(f\"   • Корреляция длина-качество: {correlation:.3f}\")\n",
    "\n",
    "# Визуализация зависимости длины от качества\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(df['technique_length'], df['quality'], alpha=0.6, color='steelblue')\n",
    "plt.xlabel('Длина техники (символы)')\n",
    "plt.ylabel('Качество')\n",
    "plt.title('📊 Зависимость качества от длины')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Добавляем линию тренда\n",
    "z = np.polyfit(df['technique_length'], df['quality'], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(df['technique_length'], p(df['technique_length']), \"r--\", alpha=0.8)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df.boxplot(column='technique_length', by='category', ax=plt.gca())\n",
    "plt.title('📏 Распределение длины по категориям')\n",
    "plt.suptitle('')  # Убираем автоматический заголовок\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Длина техники (символы)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2894c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Финальная сводка и сохранение дополнительной статистики\n",
    "\n",
    "print(\"📋 ИТОГОВАЯ СВОДКА\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Создаем сводную статистику\n",
    "summary_stats = {\n",
    "    'total_techniques': len(df),\n",
    "    'books_processed': df['book'].nunique(),\n",
    "    'categories': df['category'].nunique(),\n",
    "    'avg_quality': df['quality'].mean(),\n",
    "    'high_quality_techniques': len(df[df['quality'] >= 9]),\n",
    "    'avg_technique_length': df['technique_length'].mean(),\n",
    "    'top_category': category_counts.index[0],\n",
    "    'top_book': book_counts.index[0] if len(book_counts) > 0 else 'N/A'\n",
    "}\n",
    "\n",
    "print(f\"✨ Общие метрики:\")\n",
    "print(f\"   • Всего техник: {summary_stats['total_techniques']}\")\n",
    "print(f\"   • Обработано книг: {summary_stats['books_processed']}\")\n",
    "print(f\"   • Категорий техник: {summary_stats['categories']}\")\n",
    "print(f\"   • Среднее качество: {summary_stats['avg_quality']:.1f}/10\")\n",
    "print(f\"   • Высококачественных техник (≥9): {summary_stats['high_quality_techniques']}\")\n",
    "print(f\"   • Средняя длина техники: {summary_stats['avg_technique_length']:.0f} символов\")\n",
    "\n",
    "print(f\"\\n🏆 Лидеры:\")\n",
    "print(f\"   • Самая популярная категория: {summary_stats['top_category']}\")\n",
    "print(f\"   • Самая продуктивная книга: {summary_stats['top_book'][:40]}...\")\n",
    "\n",
    "print(f\"\\n💡 Рекомендации для улучшения:\")\n",
    "low_quality_count = len(df[df['quality'] < 7])\n",
    "if low_quality_count > 0:\n",
    "    print(f\"   • Пересмотреть {low_quality_count} техник с качеством < 7\")\n",
    "\n",
    "category_imbalance = category_counts.max() / category_counts.min()\n",
    "if category_imbalance > 3:\n",
    "    print(f\"   • Балансировать категории (дисбаланс {category_imbalance:.1f}x)\")\n",
    "\n",
    "if df['technique_length'].std() > 100:\n",
    "    print(f\"   • Стандартизировать длину техник (разброс {df['technique_length'].std():.0f})\")\n",
    "\n",
    "print(f\"\\n📁 Созданные файлы:\")\n",
    "print(f\"   • {csv_path} - основной датасет\")\n",
    "\n",
    "# Сохраняем дополнительную статистику\n",
    "summary_path = data_dir / \"processing_summary.json\"\n",
    "import json\n",
    "with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary_stats, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"   • {summary_path} - сводная статистика\")\n",
    "print(f\"\\n✅ Обработка завершена успешно!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc1300b6",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
